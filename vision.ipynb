{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14034 images belonging to 6 classes.\n",
      "Found 3000 images belonging to 6 classes.\n",
      "Epoch 1/10\n",
      "439/439 [==============================] - 502s 1s/step - loss: 1.1688 - accuracy: 0.5529 - val_loss: 0.9177 - val_accuracy: 0.6360\n",
      "Epoch 2/10\n",
      "439/439 [==============================] - 483s 1s/step - loss: 0.9143 - accuracy: 0.6588 - val_loss: 0.7420 - val_accuracy: 0.7370\n",
      "Epoch 3/10\n",
      "439/439 [==============================] - 487s 1s/step - loss: 0.8235 - accuracy: 0.6958 - val_loss: 0.6370 - val_accuracy: 0.7773\n",
      "Epoch 4/10\n",
      "439/439 [==============================] - 537s 1s/step - loss: 0.7455 - accuracy: 0.7279 - val_loss: 0.6522 - val_accuracy: 0.7760\n",
      "Epoch 5/10\n",
      "439/439 [==============================] - 1094s 2s/step - loss: 0.6951 - accuracy: 0.7488 - val_loss: 0.5952 - val_accuracy: 0.7797\n",
      "Epoch 6/10\n",
      "439/439 [==============================] - 489s 1s/step - loss: 0.6756 - accuracy: 0.7526 - val_loss: 0.5468 - val_accuracy: 0.8097\n",
      "Epoch 7/10\n",
      "439/439 [==============================] - 493s 1s/step - loss: 0.6468 - accuracy: 0.7686 - val_loss: 0.5596 - val_accuracy: 0.8087\n",
      "Epoch 8/10\n",
      "439/439 [==============================] - 461s 1s/step - loss: 0.6194 - accuracy: 0.7787 - val_loss: 0.5589 - val_accuracy: 0.8047\n",
      "Epoch 9/10\n",
      "439/439 [==============================] - 460s 1s/step - loss: 0.6045 - accuracy: 0.7842 - val_loss: 0.5112 - val_accuracy: 0.8180\n",
      "Epoch 10/10\n",
      "439/439 [==============================] - 468s 1s/step - loss: 0.6052 - accuracy: 0.7864 - val_loss: 0.5968 - val_accuracy: 0.8110\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# Direktori dataset\n",
    "train_dir = \"seg_train/seg_train\"\n",
    "val_dir = \"seg_test/seg_test\"\n",
    "# Augmentasi data\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, rotation_range=20, zoom_range=0.2, \n",
    "horizontal_flip=True)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory(train_dir, target_size=(150, 150), \n",
    "batch_size=32, class_mode='categorical')\n",
    "val_generator = val_datagen.flow_from_directory(val_dir, target_size=(150, 150), batch_size=32, \n",
    "class_mode='categorical')\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "# Definisi model CNN\n",
    "model = Sequential([\n",
    "Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
    "MaxPooling2D(2,2),\n",
    "Conv2D(64, (3,3), activation='relu'),\n",
    "MaxPooling2D(2,2),\n",
    "Flatten(),\n",
    "Dense(128, activation='relu'),\n",
    "Dropout(0.5),\n",
    "Dense(6, activation='softmax')\n",
    "])\n",
    "# Kompilasi model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# Training model\n",
    "model.fit(train_generator, validation_data=val_generator, epochs=10)\n",
    "# Simpan model\n",
    "model.save('cnn_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
